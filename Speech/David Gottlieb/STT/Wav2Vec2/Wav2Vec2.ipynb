{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Vec2 STT",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "kiMBCMb2Qjst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvW7jW1VPlPn",
        "outputId": "0da07082-f35a-4e3d-e018-4e29082faee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:748: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  FutureWarning,\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"BUT WHAT IF SOMEBODY DECIDES TO BREAK IT BE CAREFUL THAT YOU KEEP ADEQUATE COVERAGE BUT LOOK FOR PLACES TO SAVE MONEY MAYBE IT'S TAKING LONGER TO GET THINGS SQUARED AWAY THAN THE BANKERS EXPECTED HIRING THE WIFE FOR ONE'S COMPANY MAY WIN HER TAXATED RETIREMENT AND COME THE BOOST IS HELPFUL BUT INADEQUATE NEW SELF DECEIVING RAGS ARE HURRIEDLY TOSSED ON THE TWO NAKED BONES WHAT A DISCUSSION CAN ENSUE WHEN THE TITLE OF THIS TYPE OF SONG IS IN QUESTION THERE IS NO DYWING OR WAXING OR GASIN NEEDED PAPER WEIGHT MAY BE PERSONALIZED ON BACK WHILE CLAY IS LEATHER HARD PLACE WORK ON A FLAT SURFACE AND SMOOTH OUT THE SIMPLEST KIND OF SEPARATE SYSTEM USES A SINGLE SELF CONTAINED UNIT THE OLD SHOP ADAGE STILL HOLDS A GOOD MECHANIC IS USUALLY A BAD BOSS BOTH FIGURES WOULD GO HIGHER IN LATER YEARS SOME MAKE BEAUTIFUL CHAIRS CABINETS CHESTS DOLL HOUSES ET CETERA\"]\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
        "\n",
        "# load model and tokenizer\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
        "\n",
        "# The base model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio.\n",
        "# When using the model make sure that your speech input is also sampled at 16Khz.\n",
        "\n",
        "# load any audio file of your choice\n",
        "collection_of_text = []\n",
        "\n",
        "speech, rate = librosa.load(f\"[PATH_TO_FILE]\", sr=16000)\n",
        "\n",
        "input_values = tokenizer(speech, return_tensors='pt').input_values\n",
        "\n",
        "# Store logits (non-normalized predictions)\n",
        "with torch.no_grad():\n",
        "    logits = model(input_values).logits\n",
        "\n",
        "# Store predicted id's\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# decode the audio to generate text\n",
        "# Passing the prediction to the tokenzer decode to get the transcription\n",
        "transcription = tokenizer.batch_decode(predicted_ids)[0]\n",
        "collection_of_text.append(transcription)\n",
        "\n",
        "print(collection_of_text)\n",
        "final_complete_speech = \"\""
      ]
    }
  ]
}