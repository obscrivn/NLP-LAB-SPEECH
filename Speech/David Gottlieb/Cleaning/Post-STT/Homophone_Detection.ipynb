{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homophone Detection",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import Dict, List\n",
        "import re\n",
        "\n",
        "class Pyphones:\n",
        "    \n",
        "    def __init__(self, word):\n",
        "        self.word = word\n",
        "        self.url = \"https://www.homophone.com/search?page={}&type=&q={}\"\n",
        "        self.homophones = {self.word: []}\n",
        "        \n",
        "    def get_the_page(self, page_no=1):\n",
        "        \"\"\"\n",
        "        Get the page content.\n",
        "        Returns\n",
        "            str: the content of the page.\n",
        "        \"\"\"\n",
        "        url = self.url.format(page_no, self.word)\n",
        "        r = requests.get(url)\n",
        "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "        return soup\n",
        "\n",
        "    def get_the_page_nos(self):\n",
        "        \"\"\"\n",
        "        Get the total number of pages\n",
        "        Returns\n",
        "            int: the total number of the pages.\n",
        "        \"\"\"\n",
        "        soup = self.get_the_page()\n",
        "        pages = soup.find_all('div', attrs={'class':'col-sm-9'})\n",
        "        total_pages = pages[0].find('h5').text.split('/')[-1].strip()\n",
        "        return int(total_pages)\n",
        "\n",
        "    def get_the_homophones(self):\n",
        "        \"\"\"\n",
        "        Get the homophones of the word.\n",
        "        Returns\n",
        "            dict: {word: [list_of_homophones]} against each word.\n",
        "        \"\"\"\n",
        "        total_pages = self.get_the_page_nos()\n",
        "        for ix in range(total_pages):\n",
        "            page_no = ix + 1\n",
        "            soup = self.get_the_page(page_no)\n",
        "            raw_homophones = soup.find_all('div', attrs={'class': 'well well-lg'})\n",
        "            for elem in range(len(raw_homophones)):\n",
        "                raw_homophones_2 = raw_homophones[elem].find_all('a', attrs={'class': 'btn word-btn'})\n",
        "                list_of_homophones = list(raw_homophones_2)\n",
        "                if any(list_of_homophones):\n",
        "                    local_homophones = []\n",
        "                    for tag_of_homophone in list_of_homophones:\n",
        "                        homophone = tag_of_homophone.text\n",
        "                        local_homophones.append(homophone)\n",
        "                    self.homophones[self.word].append(local_homophones)\n",
        "\n",
        "        return self.homophones"
      ],
      "metadata": {
        "id": "3Pi4LhKEnyjJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'eye'\n",
        "py = Pyphones(word)\n",
        "homophones = py.get_the_homophones()\n",
        "\n",
        "for i in range(len(homophones[word])):\n",
        "  if(homophones[word][i][0]==word):\n",
        "    print(homophones[word][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYbof1KpofBx",
        "outputId": "3e38ae22-417a-463a-9ae1-e8771c07912b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eye', 'ai', 'aye', 'I']\n"
          ]
        }
      ]
    }
  ]
}